{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [] # Create a list to store the descriptions\n",
    "prices = []\n",
    "details = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = list(range(1,2))\n",
    "for page in pages:\n",
    "  req = requests.get(\"https://www.flipkart.com/clothing-and-accessories/topwear/tshirt/men-tshirt/pr?sid=clo%2Cash%2Cank%2Cedy&otracker=categorytree&otracker=nmenu_sub_Men_0_T-Shirts&page={}\".format(page)).text  # URL of the website which you want to scrape\n",
    "  #content = req.content # Get the content\n",
    "  soup = BeautifulSoup(req,'html.parser')\n",
    "  #print(soup.prettify())\n",
    "\n",
    "  desc = soup.find_all('div' , class_='_2WkVRV')\n",
    "  for i in range(len(desc)):\n",
    "    descriptions.append(desc[i].text)\n",
    "    len(descriptions)\n",
    "    \n",
    "  price = soup.find_all('div',class_='_30jeq3') \n",
    "  # Extracting price of each laptop from the website\n",
    "  for i in range(len(price)):\n",
    "    prices.append(price[i].text)\n",
    "    len(prices)\n",
    "\n",
    "  detail = soup.find_all('a',class_='IRpwTa') \n",
    "  for i in range(len(detail)):\n",
    "    details.append(detail[i].text)\n",
    "    len(details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'Product Name':descriptions,'Details':details,'Prices':prices}\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df = df.transpose()[1:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazonT-Shirt.csv',encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a570c1c9e564e66e08c537fd9c2787b22d75407af6bd0fd0606e67d7697d6a1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
